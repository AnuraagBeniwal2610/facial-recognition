{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "from sklearn import svm\n",
    "import os\n",
    "\n",
    "# Training the SVC classifier\n",
    "\n",
    "# The training data would be all the face encodings from all the known images and the labels are their names\n",
    "encodings = []\n",
    "names = []\n",
    "\n",
    "# Training directory\n",
    "train_dir = os.listdir('C:/Users/Anuraag/Desktop/FACE_REC_SVC/train_dir/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each person in the training directory\n",
    "for person in train_dir:\n",
    "    pix = os.listdir(\"C:/Users/Anuraag/Desktop/FACE_REC_SVC/train_dir/\" + person)\n",
    "\n",
    "    # Loop through each training image for the current person\n",
    "    for person_img in pix:\n",
    "        # Get the face encodings for the face in each image file\n",
    "        face = face_recognition.load_image_file(\"C:/Users/Anuraag/Desktop/FACE_REC_SVC/train_dir/\" + person + \"/\" + person_img)\n",
    "        face_bounding_boxes = face_recognition.face_locations(face)\n",
    "\n",
    "        #If training image contains exactly one face\n",
    "        if len(face_bounding_boxes) == 1:\n",
    "            face_enc = face_recognition.face_encodings(face)[0]\n",
    "            # Add face encoding for current image with corresponding label (name) to the training data\n",
    "            encodings.append(face_enc)\n",
    "            names.append(person)\n",
    "        else:\n",
    "            print(person + \"/\" + person_img + \" was skipped and can't be used for training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the SVC classifier\n",
    "clf = svm.SVC(gamma='scale',probability=True)\n",
    "clf.fit(encodings,names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test image with unknown faces into a numpy array\n",
    "test_image = face_recognition.load_image_file('rishav.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected:  1\n"
     ]
    }
   ],
   "source": [
    "# Find all the faces in the test image using the default HOG-based model\n",
    "face_locations = face_recognition.face_locations(test_image)\n",
    "no = len(face_locations)\n",
    "print(\"Number of faces detected: \", no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080_TrainSet\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Predict all the faces in the test image using the trained classifier\n",
    "for i in range(no):\n",
    "    test_image_enc = face_recognition.face_encodings(test_image)[i]\n",
    "\n",
    "thresh = clf.predict_proba([test_image_enc])\n",
    "result = []\n",
    "\n",
    "\n",
    "for prob in thresh:\n",
    "    if (prob > 0.1).any():\n",
    "        result = np.where(prob > 0.1, True, False)\n",
    "        res = [i for i, val in enumerate(result) if val]\n",
    "        integers = res\n",
    "        strings = [str(integer) for integer in integers]\n",
    "        a_string = \"\".join(strings)\n",
    "        an_integer = int(a_string)\n",
    "        print(train_dir[an_integer])\n",
    "    else:\n",
    "        print(\"UNKNOWN USER\")\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [i for i, val in enumerate(result) if val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-503c48e45fc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'list'"
     ]
    }
   ],
   "source": [
    "int(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2080_TrainSet\n"
     ]
    }
   ],
   "source": [
    "integers = res\n",
    "strings = [str(integer) for integer in integers]\n",
    "a_string = \"\".join(strings)\n",
    "an_integer = int(a_string)\n",
    "print(train_dir[an_integer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "an_integer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2080_TrainSet'"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir[an_integer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def face_distance(face_encodings, face_to_compare):\n",
      "    \"\"\"\n",
      "    Given a list of face encodings, compare them to a known face encoding and get a euclidean distance\n",
      "    for each comparison face. The distance tells you how similar the faces are.\n",
      "\n",
      "    :param faces: List of face encodings to compare\n",
      "    :param face_to_compare: A face encoding to compare against\n",
      "    :return: A numpy ndarray with the distance for each face in the same order as the 'faces' array\n",
      "    \"\"\"\n",
      "    if len(face_encodings) == 0:\n",
      "        return np.empty((0))\n",
      "\n",
      "    return np.linalg.norm(face_encodings - face_to_compare, axis=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(face_recognition.face_distance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(self, X):\n",
    "        X = self._validate_for_predict(X)\n",
    "        if self.probA_.size == 0 or self.probB_.size == 0:\n",
    "            raise NotFittedError(\"predict_proba is not available when fitted \"\n",
    "                                 \"with probability=False\")\n",
    "        pred_proba = (self._sparse_predict_proba\n",
    "                      if self._sparse else self._dense_predict_proba)\n",
    "        return pred_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07587452,  0.05103988,  0.06536067, -0.070502  , -0.0689613 ,\n",
       "        0.03409624, -0.07662652, -0.05327453,  0.17069344, -0.12397216,\n",
       "        0.15282609,  0.02278751, -0.25807068, -0.08006322,  0.00272965,\n",
       "        0.0854871 , -0.09514973, -0.1476296 , -0.03750812, -0.06055036,\n",
       "        0.03416342,  0.0433097 , -0.04838351,  0.01137434, -0.19415629,\n",
       "       -0.40063313, -0.07497474, -0.04564691,  0.02255776, -0.07287352,\n",
       "       -0.01812377, -0.03656858, -0.20858032, -0.04230921,  0.00557476,\n",
       "        0.17520699, -0.0687692 , -0.0068022 ,  0.11425475,  0.03522688,\n",
       "       -0.18424778,  0.01313738,  0.00092757,  0.23363584,  0.12707891,\n",
       "        0.12128229,  0.05913115, -0.11417308,  0.09401167, -0.25824758,\n",
       "        0.12900564,  0.11339811,  0.04333611,  0.05633807,  0.1027469 ,\n",
       "       -0.21185872,  0.01360624,  0.15175021, -0.24573714,  0.10460044,\n",
       "        0.02110958, -0.06688368, -0.04562785,  0.01266521,  0.23023781,\n",
       "        0.10056157, -0.09331366, -0.14959587,  0.21305402, -0.18536307,\n",
       "       -0.00093016,  0.06148966,  0.01099086, -0.1903064 , -0.28077939,\n",
       "        0.09028821,  0.36384338,  0.16416557, -0.1547655 ,  0.0872588 ,\n",
       "       -0.06735149,  0.01334351,  0.12849791,  0.00066432, -0.08250543,\n",
       "        0.0524787 , -0.0988991 ,  0.04923471,  0.18584161,  0.04739914,\n",
       "        0.01744799,  0.22483559,  0.00348519,  0.06516493,  0.10234529,\n",
       "        0.07153181, -0.1645011 ,  0.02942654, -0.12056649, -0.04871534,\n",
       "        0.17308888, -0.09208452,  0.08488968,  0.08094468, -0.20209858,\n",
       "        0.21419188, -0.02082093, -0.02647938,  0.07174611,  0.01565593,\n",
       "       -0.13675357, -0.03829207,  0.19762783, -0.34515887,  0.24284118,\n",
       "        0.16287926,  0.02378612,  0.2047466 ,  0.14006513,  0.03933328,\n",
       "        0.01119515, -0.09461858, -0.20851028, -0.05420312,  0.0132125 ,\n",
       "       -0.06986983,  0.09379768,  0.0759183 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all the faces in the test image using the trained classifier\n",
    "print(\"Found:\")\n",
    "for i in range(no):\n",
    "    test_image_enc = face_recognition.face_encodings(test_image)[i]\n",
    "    name = clf.predict([test_image_enc])\n",
    "    print(*name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba([test_image_enc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = clf.predict_proba([test_image_enc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = []\n",
    "for x in thresh:\n",
    "    record.append(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = clf.predict_proba([test_image_enc])\n",
    "for prob in thresh:\n",
    "    if (prob > 0.1).any():\n",
    "        name = clf.predict([test_image_enc])\n",
    "        print(*name)\n",
    "    else:\n",
    "        print(\"UNKNOWN USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for x in thresh:\n",
    "    result.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1168_TrainSet',\n",
       " '2014_TrainSet',\n",
       " '2025_TrainSet',\n",
       " '2066_TrainSet',\n",
       " '2071_TrainSet',\n",
       " '2080_TrainSet',\n",
       " '2085_TrainSet',\n",
       " '2108_TrainSet',\n",
       " '2118_TrainSet',\n",
       " '2126_TrainSet',\n",
       " '2136_TrainSet',\n",
       " '2142_TrainSet',\n",
       " '2143_TrainSet',\n",
       " '2160_TrainSet',\n",
       " '2193_TrainSet',\n",
       " '2221_TrainSet',\n",
       " '2222_TrainSet',\n",
       " '2253_TrainSet',\n",
       " '2272_TrainSet',\n",
       " '2273_TrainSet',\n",
       " '2285_TrainSet',\n",
       " '2298_TrainSet',\n",
       " '2313_TrainSet',\n",
       " '2319_TrainSet',\n",
       " '2326_TrainSet',\n",
       " '2336_TrainSet',\n",
       " '2365_TrainSet',\n",
       " '2377_TrainSet',\n",
       " '2381_TrainSet',\n",
       " '2385_TrainSet',\n",
       " '2386_TrainSet',\n",
       " '341_TrainSet',\n",
       " '358_TrainSet',\n",
       " '671_TrainSet',\n",
       " '814_TrainSet',\n",
       " '868_TrainSet',\n",
       " '945_TrainSet',\n",
       " '967_TrainSet',\n",
       " '987_TrainSet',\n",
       " 'govinda']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0.00583275, 0.01052323, 0.02954194, 0.00913531, 0.01332145,\n",
       "         0.01455258, 0.01075249, 0.01516847, 0.01449689, 0.01302138,\n",
       "         0.01083431, 0.00733087, 0.00660897, 0.00690465, 0.00936084,\n",
       "         0.01820849, 0.01613005, 0.00904397, 0.02523378, 0.00965206,\n",
       "         0.01059148, 0.01722952, 0.00742081, 0.01385429, 0.01435771,\n",
       "         0.01476683, 0.01238811, 0.01113091, 0.0076842 , 0.02202038,\n",
       "         0.00739107, 0.0149573 , 0.00726177, 0.00705543, 0.00701035,\n",
       "         0.01601127, 0.01172551, 0.01451681, 0.00442918, 0.5225426 ]),\n",
       "  '1168_TrainSet')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(result,train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'join'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-b5fe67a7c070>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'join'"
     ]
    }
   ],
   "source": [
    "print(result.join(train_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple images per person\n",
    "# Find and recognize faces in an image using a SVC with scikit-learn\n",
    "\n",
    "\"\"\"\n",
    "Structure:\n",
    "        <test_image>.jpg\n",
    "        <train_dir>/\n",
    "            <person_1>/\n",
    "                <person_1_face-1>.jpg\n",
    "                <person_1_face-2>.jpg\n",
    "                .\n",
    "                .\n",
    "                <person_1_face-n>.jpg\n",
    "           <person_2>/\n",
    "                <person_2_face-1>.jpg\n",
    "                <person_2_face-2>.jpg\n",
    "                .\n",
    "                .\n",
    "                <person_2_face-n>.jpg\n",
    "            .\n",
    "            .\n",
    "            <person_n>/\n",
    "                <person_n_face-1>.jpg\n",
    "                <person_n_face-2>.jpg\n",
    "                .\n",
    "                .\n",
    "                <person_n_face-n>.jpg\n",
    "\"\"\"\n",
    "\n",
    "import face_recognition\n",
    "from sklearn import svm\n",
    "import os\n",
    "\n",
    "# Training the SVC classifier\n",
    "\n",
    "# The training data would be all the face encodings from all the known images and the labels are their names\n",
    "encodings = []\n",
    "names = []\n",
    "\n",
    "# Training directory\n",
    "train_dir = os.listdir('C:/Users/Anuraag/Desktop/FACE_REC_SVC/train_dir/')\n",
    "\n",
    "# Loop through each person in the training directory\n",
    "for person in train_dir:\n",
    "    pix = os.listdir(\"C:/Users/Anuraag/Desktop/FACE_REC_SVC/train_dir/\" + person)\n",
    "\n",
    "    # Loop through each training image for the current person\n",
    "    for person_img in pix:\n",
    "        # Get the face encodings for the face in each image file\n",
    "        face = face_recognition.load_image_file(\"C:/Users/Anuraag/Desktop/FACE_REC_SVC/train_dir/\" + person + \"/\" + person_img)\n",
    "        face_bounding_boxes = face_recognition.face_locations(face)\n",
    "\n",
    "        #If training image contains exactly one face\n",
    "        if len(face_bounding_boxes) == 1:\n",
    "            face_enc = face_recognition.face_encodings(face)[0]\n",
    "            # Add face encoding for current image with corresponding label (name) to the training data\n",
    "            encodings.append(face_enc)\n",
    "            names.append(person)\n",
    "        else:\n",
    "            print(person + \"/\" + person_img + \" was skipped and can't be used for training\")\n",
    "\n",
    "# Create and train the SVC classifier\n",
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(encodings,names)\n",
    "\n",
    "# Load the test image with unknown faces into a numpy array\n",
    "test_image = face_recognition.load_image_file('test_image.jpg')\n",
    "\n",
    "# Find all the faces in the test image using the default HOG-based model\n",
    "face_locations = face_recognition.face_locations(test_image)\n",
    "no = len(face_locations)\n",
    "print(\"Number of faces detected: \", no)\n",
    "\n",
    "# Predict all the faces in the test image using the trained classifier\n",
    "print(\"Found:\")\n",
    "for i in range(no):\n",
    "    test_image_enc = face_recognition.face_encodings(test_image)[i]\n",
    "    name = clf.predict([test_image_enc])\n",
    "    print(*name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
